warning(paste("process_all_surface: Deck light measurements not found in" , paste(dir.list[t])))
} else {
#Import first deck file
deck.data <- read.csv(file = deck.files[1], header = F)
deck.data$ctime <- paste(deck.data[,1], deck.data[,2], sep = " ")
#print("b")
# Import additional deck files if multiple exist in one directory
if(length(deck.files) > 1) {
for(b in 2:length(deck.files)) {
deck.data <- rbind(deck.data, read.csv(file = deck.files[b], header = F))
}
}
#print(deck.data[1,])
# Convert times into POSIXct
deck.data$ctime <- as.POSIXct(strptime(deck.data$ctime, format = "%m/%d/%Y %H:%M:%S", tz = "America/Anchorage"))
#print("d")
# Convert cast times to POSIXct format, add 30 second offset to each cast time to avoid truncating cast data
cast.times$downcast_start <- as.POSIXct(strptime(cast.times$downcast_start, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) - time.buffer
cast.times$downcast_end <- as.POSIXct(strptime(cast.times$downcast_end, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) +  time.buffer
cast.times$upcast_start <- as.POSIXct(strptime(cast.times$upcast_start, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) - time.buffer
cast.times$upcast_end <- as.POSIXct(strptime(cast.times$upcast_end, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) + time.buffer
#print("e")
#print(1)
# Correct cases where there is a mismatch between survey time and tag time
deck.data <- time_adjustments(light.data = deck.data,
cast.data = cast.times)
#print(2)
if(nrow(deck.data) > 0) {
#print(3)
surface_profiles <- surface_light(light.data = deck.data,
cast.data = cast.times)
if(surface.output){
#print(4)
surface.output <- surface_profiles
#print(5)
} else {
#print(6)
surface.output <- rbind(surface.output, surface_profiles)
#print(7)
}
}
}
}
return(surface.output)
}
test <- process_all_surface(dir.list = light.dir)
table(test$updown, test$cruise)
test <- process_all_surface(dir.list = light.dir[10:11])
table(test$updown, test$cruise)
process_all_surface <- function(dir.list, time.buffer = 40, ...) {
surface.output <- TRUE
for(t in 1:length(dir.list)) {
# Check for CastTimes
if(!file.exists(paste(dir.list[t], "/CastTimes.csv", sep = ""))) {
stop(paste("process_all_surface: CastTimes.csv not found in" , paste(dir.list[t])))
}
# Import CastTImes
cast.times <- read.csv(paste(dir.list[t], "/CastTimes.csv", sep = ""))
#print("a")
# Find names of deck files
deck.files <- list.files(path = dir.list[t], pattern = "^deck.*\\.csv", full.names = T)
# Check for CastTimes
if(length(deck.files) < 1) {
warning(paste("process_all_surface: Deck light measurements not found in" , paste(dir.list[t])))
} else {
#Import first deck file
deck.data <- read.csv(file = deck.files[1], header = F)
deck.data$ctime <- paste(deck.data[,1], deck.data[,2], sep = " ")
#print("b")
# Import additional deck files if multiple exist in one directory
if(length(deck.files) > 1) {
for(b in 2:length(deck.files)) {
deck.data <- rbind(deck.data, read.csv(file = deck.files[b], header = F))
}
}
#print(deck.data[1,])
# Convert times into POSIXct
deck.data$ctime <- as.POSIXct(strptime(deck.data$ctime, format = "%m/%d/%Y %H:%M:%S", tz = "America/Anchorage"))
#print("d")
# Convert cast times to POSIXct format, add 30 second offset to each cast time to avoid truncating cast data
cast.times$downcast_start <- as.POSIXct(strptime(cast.times$downcast_start, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) - time.buffer
cast.times$downcast_end <- as.POSIXct(strptime(cast.times$downcast_end, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) +  time.buffer
cast.times$upcast_start <- as.POSIXct(strptime(cast.times$upcast_start, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) - time.buffer
cast.times$upcast_end <- as.POSIXct(strptime(cast.times$upcast_end, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) + time.buffer
#print("e")
#print(1)
# Correct cases where there is a mismatch between survey time and tag time
deck.data <- time_adjustments(light.data = deck.data,
cast.data = cast.times)
#print(2)
if(nrow(deck.data) > 0) {
#print(3)
surface_profiles <- surface_light(light.data = deck.data,
cast.data = cast.times)
if(surface.output){
#print(4)
surface.output <- surface_profiles
#print(5)
} else {
#print(6)
surface.output <- rbind(surface.output, surface_profiles)
#print(7)
}
}
}
}
return(surface.output)
}
test <- process_all_surface(dir.list = light.dir[10:11])
table(test$updown, test$cruise)
process_all_surface <- function(dir.list, time.buffer = 40, ...) {
surface.output <- TRUE
for(t in 1:length(dir.list)) {
# Check for CastTimes
if(!file.exists(paste(dir.list[t], "/CastTimes.csv", sep = ""))) {
stop(paste("process_all_surface: CastTimes.csv not found in" , paste(dir.list[t])))
}
# Import CastTImes
cast.times <- read.csv(paste(dir.list[t], "/CastTimes.csv", sep = ""))
#print("a")
# Find names of deck files
deck.files <- list.files(path = dir.list[t], pattern = "^deck.*\\.csv", full.names = T)
# Check for CastTimes
if(length(deck.files) < 1) {
warning(paste("process_all_surface: Deck light measurements not found in" , paste(dir.list[t])))
} else {
#Import first deck file
deck.data <- read.csv(file = deck.files[1], header = F)
deck.data$ctime <- paste(deck.data[,1], deck.data[,2], sep = " ")
#print("b")
# Import additional deck files if multiple exist in one directory
if(length(deck.files) > 1) {
for(b in 2:length(deck.files)) {
deck.data <- rbind(deck.data, read.csv(file = deck.files[b], header = F))
}
}
#print(deck.data[1,])
# Convert times into POSIXct
deck.data$ctime <- as.POSIXct(strptime(deck.data$ctime, format = "%m/%d/%Y %H:%M:%S", tz = "America/Anchorage"))
#print("d")
# Convert cast times to POSIXct format, add 30 second offset to each cast time to avoid truncating cast data
cast.times$downcast_start <- as.POSIXct(strptime(cast.times$downcast_start, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) - time.buffer
cast.times$downcast_end <- as.POSIXct(strptime(cast.times$downcast_end, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) +  time.buffer
cast.times$upcast_start <- as.POSIXct(strptime(cast.times$upcast_start, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) - time.buffer
cast.times$upcast_end <- as.POSIXct(strptime(cast.times$upcast_end, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) + time.buffer
#print("e")
#print(1)
# Correct cases where there is a mismatch between survey time and tag time
deck.data <- time_adjustments(light.data = deck.data,
cast.data = cast.times)
#print(2)
if(nrow(deck.data) > 0) {
#print(3)
surface_profiles <- surface_light(light.data = deck.data,
cast.data = cast.times)
print(surface.output)
if(surface.output){
#print(4)
surface.output <- surface_profiles
#print(5)
} else {
#print(6)
surface.output <- rbind(surface.output, surface_profiles)
#print(7)
}
}
}
}
return(surface.output)
}
test <- process_all_surface(dir.list = light.dir[10:11])
process_all_surface <- function(dir.list, time.buffer = 40, ...) {
surface.output <- NULL
for(t in 1:length(dir.list)) {
# Check for CastTimes
if(!file.exists(paste(dir.list[t], "/CastTimes.csv", sep = ""))) {
stop(paste("process_all_surface: CastTimes.csv not found in" , paste(dir.list[t])))
}
# Import CastTImes
cast.times <- read.csv(paste(dir.list[t], "/CastTimes.csv", sep = ""))
#print("a")
# Find names of deck files
deck.files <- list.files(path = dir.list[t], pattern = "^deck.*\\.csv", full.names = T)
# Check for CastTimes
if(length(deck.files) < 1) {
warning(paste("process_all_surface: Deck light measurements not found in" , paste(dir.list[t])))
} else {
#Import first deck file
deck.data <- read.csv(file = deck.files[1], header = F)
deck.data$ctime <- paste(deck.data[,1], deck.data[,2], sep = " ")
#print("b")
# Import additional deck files if multiple exist in one directory
if(length(deck.files) > 1) {
for(b in 2:length(deck.files)) {
deck.data <- rbind(deck.data, read.csv(file = deck.files[b], header = F))
}
}
#print(deck.data[1,])
# Convert times into POSIXct
deck.data$ctime <- as.POSIXct(strptime(deck.data$ctime, format = "%m/%d/%Y %H:%M:%S", tz = "America/Anchorage"))
#print("d")
# Convert cast times to POSIXct format, add 30 second offset to each cast time to avoid truncating cast data
cast.times$downcast_start <- as.POSIXct(strptime(cast.times$downcast_start, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) - time.buffer
cast.times$downcast_end <- as.POSIXct(strptime(cast.times$downcast_end, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) +  time.buffer
cast.times$upcast_start <- as.POSIXct(strptime(cast.times$upcast_start, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) - time.buffer
cast.times$upcast_end <- as.POSIXct(strptime(cast.times$upcast_end, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) + time.buffer
#print("e")
#print(1)
# Correct cases where there is a mismatch between survey time and tag time
deck.data <- time_adjustments(light.data = deck.data,
cast.data = cast.times)
#print(2)
if(nrow(deck.data) > 0) {
#print(3)
surface_profiles <- surface_light(light.data = deck.data,
cast.data = cast.times)
print(surface.output)
if(is.null(surface.output)) {
#print(4)
surface.output <- surface_profiles
#print(5)
} else {
#print(6)
surface.output <- rbind(surface.output, surface_profiles)
#print(7)
}
}
}
}
return(surface.output)
}
test <- process_all_surface(dir.list = light.dir[10:11])
table(test$updown, test$cruise)
process_all_surface <- function(dir.list, time.buffer = 40, ...) {
surface.output <- NULL
for(t in 1:length(dir.list)) {
# Check for CastTimes
if(!file.exists(paste(dir.list[t], "/CastTimes.csv", sep = ""))) {
stop(paste("process_all_surface: CastTimes.csv not found in" , paste(dir.list[t])))
}
# Import CastTImes
cast.times <- read.csv(paste(dir.list[t], "/CastTimes.csv", sep = ""))
#print("a")
# Find names of deck files
deck.files <- list.files(path = dir.list[t], pattern = "^deck.*\\.csv", full.names = T)
# Check for CastTimes
if(length(deck.files) < 1) {
warning(paste("process_all_surface: Deck light measurements not found in" , paste(dir.list[t])))
} else {
#Import first deck file
deck.data <- read.csv(file = deck.files[1], header = F)
deck.data$ctime <- paste(deck.data[,1], deck.data[,2], sep = " ")
#print("b")
# Import additional deck files if multiple exist in one directory
if(length(deck.files) > 1) {
for(b in 2:length(deck.files)) {
deck.data <- rbind(deck.data, read.csv(file = deck.files[b], header = F))
}
}
#print(deck.data[1,])
# Convert times into POSIXct
deck.data$ctime <- as.POSIXct(strptime(deck.data$ctime, format = "%m/%d/%Y %H:%M:%S", tz = "America/Anchorage"))
#print("d")
# Convert cast times to POSIXct format, add 30 second offset to each cast time to avoid truncating cast data
cast.times$downcast_start <- as.POSIXct(strptime(cast.times$downcast_start, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) - time.buffer
cast.times$downcast_end <- as.POSIXct(strptime(cast.times$downcast_end, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) +  time.buffer
cast.times$upcast_start <- as.POSIXct(strptime(cast.times$upcast_start, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) - time.buffer
cast.times$upcast_end <- as.POSIXct(strptime(cast.times$upcast_end, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) + time.buffer
#print("e")
#print(1)
# Correct cases where there is a mismatch between survey time and tag time
deck.data <- time_adjustments(light.data = deck.data,
cast.data = cast.times)
#print(2)
if(nrow(deck.data) > 0) {
#print(3)
surface_profiles <- surface_light(light.data = deck.data,
cast.data = cast.times)
if(is.null(surface.output)) {
#print(4)
surface.output <- surface_profiles
#print(5)
} else {
#print(6)
surface.output <- rbind(surface.output, surface_profiles)
#print(7)
}
}
}
}
return(surface.output)
}
test <- process_all_surface(dir.list = light.dir)
process_all_surface <- function(dir.list, ...) {
surface.output <- NULL
for(t in 1:length(dir.list)) {
# Check for CastTimes
if(!file.exists(paste(dir.list[t], "/CastTimes.csv", sep = ""))) {
stop(paste("process_all_surface: CastTimes.csv not found in" , paste(dir.list[t])))
}
# Import CastTImes
cast.times <- read.csv(paste(dir.list[t], "/CastTimes.csv", sep = ""))
#print("a")
# Find names of deck files
deck.files <- list.files(path = dir.list[t], pattern = "^deck.*\\.csv", full.names = T)
# Check for CastTimes
if(length(deck.files) < 1) {
warning(paste("process_all_surface: Deck light measurements not found in" , paste(dir.list[t])))
} else {
#Import first deck file
deck.data <- read.csv(file = deck.files[1], header = F)
deck.data$ctime <- paste(deck.data[,1], deck.data[,2], sep = " ")
#print("b")
# Import additional deck files if multiple exist in one directory
if(length(deck.files) > 1) {
for(b in 2:length(deck.files)) {
deck.data <- rbind(deck.data, read.csv(file = deck.files[b], header = F))
}
}
#print(deck.data[1,])
# Convert times into POSIXct
deck.data$ctime <- as.POSIXct(strptime(deck.data$ctime, format = "%m/%d/%Y %H:%M:%S", tz = "America/Anchorage"))
#print("d")
# Convert cast times to POSIXct format, add 30 second offset to each cast time to avoid truncating cast data
cast.times$downcast_start <- as.POSIXct(strptime(cast.times$downcast_start, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage"))
cast.times$downcast_end <- as.POSIXct(strptime(cast.times$downcast_end, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage"))
cast.times$upcast_start <- as.POSIXct(strptime(cast.times$upcast_start, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage"))
cast.times$upcast_end <- as.POSIXct(strptime(cast.times$upcast_end, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage"))
#print("e")
#print(1)
# Correct cases where there is a mismatch between survey time and tag time
deck.data <- time_adjustments(light.data = deck.data,
cast.data = cast.times)
#print(2)
if(nrow(deck.data) > 0) {
#print(3)
# Find surface measurements
surface_profiles <- surface_light(light.data = deck.data,
cast.data = cast.times,
...)
if(is.null(surface.output)) {
#print(4)
surface.output <- surface_profiles
#print(5)
} else {
#print(6)
surface.output <- rbind(surface.output, surface_profiles)
#print(7)
}
}
}
}
return(surface.output)
}
surface_light <- function(light.data, cast.data, time.buffer = 30, ...) {
# light_data <- read.csv(light.data, header = F)
# light_data$ctime <- paste(light_data[,1], light_data[,2], sep = " ")
#
# # Convert light data to POSIXct format
# light_data$ctime <- as.POSIXct(strptime(light_data$ctime, format = "%m/%d/%Y %H:%M:%S", tz = "America/Anchorage"))
#
# cast_data <- read.csv(cast.data)
#
# # Convert cast times to POSIXct format, add 30 second offset to each cast time to avoid truncating cast data
# cast_data$downcast_start <- as.POSIXct(strptime(cast_data$downcast_start, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) - time.buffer
# cast_data$downcast_end <- as.POSIXct(strptime(cast_data$downcast_end, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) +  time.buffer
# cast_data$upcast_start <- as.POSIXct(strptime(cast_data$upcast_start, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) - time.buffer
# cast_data$upcast_end <- as.POSIXct(strptime(cast_data$upcast_end, format = "%Y-%m-%d %H:%M:%S", tz = "America/Anchorage")) + time.buffer
#
# #### REMOVE THIS PRIOR TO USE
# # Offsets for tags set to the wrong time zone
# if(cast_data$cruise[1] == 201601) {
#   print("Correcting 2016")
#   light_data$ctime <- light_data$ctime + 3600
# } else if(cast_data$vessel[1] == 162 & cast_data$cruise[1] == 201101) {
#   print("Correcting 162-201101")
#   light_data$ctime <- light_data$ctime + (3600*8)
# }
# Select and rename light and time columns
light.data <- light.data[,5:6]
colnames(light.data) <- c("surf_llight", "ctime")
light.data$surf_trans_llight <- convert_light(light.data$surf_llight)
light.data$vessel <- rep(cast.data$vessel[1], nrow(light.data))
light.data$cruise <- rep(cast.data$cruise[1], nrow(light.data))
# Create empty rows for cast direction (updown) and haul number
haul_count <- nrow(cast.data)
for(i in 1:haul_count) {
# Assign upcast or downcast to tag time
light.data$updown[light.data$ctime > (cast.data$downcast_start[i] - time.buffer) &
light.data$ctime < (cast.data$downcast_start[i] + time.buffer)] <- "Downcast"
light.data$updown[light.data$ctime > (cast.data$upcast_start[i] - time.buffer) &
light.data$ctime < (cast.data$upcast_end[i] + time.buffer)] <- "Upcast"
light.data$haul[light.data$ctime > (cast.data$downcast_start[i] - time.buffer) &
light.data$ctime < (cast.data$upcast_end[i] + time.buffer)] <- cast.data$haul[i]
}
# Remove on-bottom and errant sampling not from casts
light.data <- subset(light.data, is.na(updown) == F)
# Geometric mean and geometric standard deviation surface light during casts
light.data <- aggregate(surf_trans_llight ~ haul + updown + vessel + cruise, data = light.data, FUN = geometric.mean)
# light_cast_stdev <- aggregate(surf_trans_llight ~ haul + updown + vessel + cruise, data = light_data, FUN = geometric.sd)
# colnames(light_cast_stdev)[5] <- "sd_surf_trans_llight"
# light_cast_times <- aggregate(ctime ~ haul + updown + vessel + cruise, data = light_data, FUN = mean)
# light_cast_times$ctime <- with_tz(light_cast_times$ctime, tzone = "America/Anchorage")
# light_data_casts <- merge(light_data_casts, light_cast_stdev)
# light_data_casts <- merge(light_data_casts, light_cast_times)
return(light.data)
}
# Wrapper function which runs TLUtilities::time_adjustments() and TLUtilities::surface_light()
test <- process_all_surface(dir.list = light.dir[10:11])
table(test$updown, test$cruise)
# Wrapper function which runs TLUtilities::time_adjustments() and TLUtilities::surface_light().
test <- process_all_surface(dir.list = light.dir, time.buffer = 30)
dir()
getwd()
setwd("C:/Users/seanr/OneDrive/Thesis/Chapter 1 - Visual Foraging Condition in the Eastern Bering Sea")
getwd()
setwd("C:/Users/seanr/OneDrive/Thesis/Chapter 1 - Visual Foraging Condition in the Eastern Bering Sea/data")
getwd()
dirlist <- read.csv(file = "C:/Users/seanr/OneDrive/Thesis/Chapter 1 - Visual Foraging Condition in the Eastern Bering Sea/data/fileinv_lightdata_directory.csv")
dirlist
require(trawllight)
require(trawllight)
require(trawllight)
library(trawllight)
rm(list = ls())
# Import filepaths for trawl light DIRECTORIES. Each target directories should contain corr_Mk9Hauls.csv, deck1**.csv, and CastTimes.csv for a vessel/cruise combination.
light.dir <- read.csv("D:/Projects/OneDrive/Thesis/Chapter 1 - Visual Foraging Condition in the Eastern Bering Sea/data/fileinv_lightdata_directory.csv", stringsAsFactors = F, header = F)
# Only select directories for the EBS shelf
light.dir <- light.dir[which(grepl("ebs", light.dir[,1])),1]
# Wrapper function which runs TLUtilies::vertical_profiles(), trawllight::filter_stepwise(), and trawllight::calculate_attenuation() for every cast in each of the target directories. It is advisable to process only a few dierectories at a time due R memory limits and the potential for processing errors to occur. "Downcast" and "Upcast" should be processed separately.
ebs_04 <- process_all(dir.structure = light.dir[1],
cast.dir = "Downcast",
silent = F)
#source("vertical_profiles.R")
source("process_all.R")
getwd
getwd()
#source("vertical_profiles.R")
source("./R/process_all.R")
# Only select directories for the EBS shelf
light.dir <- light.dir[which(grepl("ebs", light.dir[,1])),1]
dir()
# Import filepaths for trawl light DIRECTORIES. Each target directories should contain corr_Mk9Hauls.csv, deck1**.csv, and CastTimes.csv for a vessel/cruise combination.
light.dir <- read.csv("D:/Projects/OneDrive/Thesis/Chapter 1 - Visual Foraging Condition in the Eastern Bering Sea/data/fileinv_lightdata_directory.csv", stringsAsFactors = F, header = F)
# Only select directories for the EBS shelf
light.dir <- light.dir[which(grepl("ebs", light.dir[,1])),1]
# Wrapper function which runs TLUtilies::vertical_profiles(), trawllight::filter_stepwise(), and trawllight::calculate_attenuation() for every cast in each of the target directories. It is advisable to process only a few dierectories at a time due R memory limits and the potential for processing errors to occur. "Downcast" and "Upcast" should be processed separately.
ebs_04 <- process_all(dir.structure = light.dir[1],
cast.dir = "Downcast",
silent = F)
#source("vertical_profiles.R")
source(".R/process_all.R")
source("./R/vertical_profiles.R")
source("./R/process_all.R")
# Wrapper function which runs TLUtilies::vertical_profiles(), trawllight::filter_stepwise(), and trawllight::calculate_attenuation() for every cast in each of the target directories. It is advisable to process only a few dierectories at a time due R memory limits and the potential for processing errors to occur. "Downcast" and "Upcast" should be processed separately.
ebs_04 <- process_all(dir.structure = light.dir[1],
cast.dir = "Downcast",
silent = F)
# Wrapper function which runs TLUtilities::time_adjustments() and TLUtilities::surface_light().
test <- process_all_surface(dir.list = light.dir, time.buffer = 30)
source("./R/process_all_sruface.R")
source("./R/process_all_surface.R")
# Wrapper function which runs TLUtilities::time_adjustments() and TLUtilities::surface_light().
test <- process_all_surface(dir.list = light.dir, time.buffer = 30)
?source
source("./R")
source("./R/")
dir("./R/")
sapply(paste("./R/", dir("./R/"), sep = ""),source,.GlobalEnv)
rm(list = ls())
sapply(paste("./R/", dir("./R/"), sep = ""), source)
rm(list = ls())
library(trawllight)
rm(list = ls())
# source TLUtilities functions for testing
sapply(paste("./R/", dir("./R/"), sep = ""), source)
# Import filepaths for trawl light DIRECTORIES. Each target directories should contain corr_Mk9Hauls.csv, deck1**.csv, and CastTimes.csv for a vessel/cruise combination.
light.dir <- read.csv("D:/Projects/OneDrive/Thesis/Chapter 1 - Visual Foraging Condition in the Eastern Bering Sea/data/fileinv_lightdata_directory.csv", stringsAsFactors = F, header = F)
# Only select directories for the EBS shelf
light.dir <- light.dir[which(grepl("ebs", light.dir[,1])),1]
# Wrapper function which runs TLUtilies::vertical_profiles(), trawllight::filter_stepwise(), and trawllight::calculate_attenuation() for every cast in each of the target directories. It is advisable to process only a few dierectories at a time due R memory limits and the potential for processing errors to occur. "Downcast" and "Upcast" should be processed separately.
ebs_04 <- process_all(dir.structure = light.dir[1],
cast.dir = "Downcast",
silent = F)
# Wrapper function which runs TLUtilities::time_adjustments() and TLUtilities::surface_light().
test <- process_all_surface(dir.list = light.dir, time.buffer = 30)
test
print(head(ebs_04))
str(ebs_04)
names(ebs_04)
print(light.dir)
print(head(light.dir))
light.dr
light.dir
light.dir[10]
# Wrapper function which runs TLUtilies::vertical_profiles(), trawllight::filter_stepwise(), and trawllight::calculate_attenuation() for every cast in each of the target directories. It is advisable to process only a few dierectories at a time due R memory limits and the potential for processing errors to occur. "Downcast" and "Upcast" should be processed separately. Here, I only use the 10th directory for Vessel 89, Cruise 200801
ebs <- process_all(dir.structure = light.dir[10],
cast.dir = "Downcast",
silent = F)
# Examine the contents of this
print(names(ebs))
print(head(ebs$loess_eval))
print(head(ebs$atten_values))
print(tail(ebs$atten_values))
# ebs is a list containing four data frames: loess_eval, atten_values,
print(names(ebs))
# ebs is a list containing four data frames: loess_eval, atten_values, light_ratios
print(names(ebs))
# light_ratios
print(head(ebs$light_ratios))
# light_ratios
print(head(ebs$light_ratios))
