---
title: "TLUtilities"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This package contains functions designed to process RACE light data using functions in the trawllight package. While trawllight provides functions to process light data, it is designed to work for a generic data structure, rather than being tailored to specifically processing RACE data. TLUtilities provides functions to read-in RACE data and iterate over casts to estimate optical parameters.


This document demonstrates how light data is processed using TLUtilities and trawllight.

## Installing trawllight and TLUtilities

Install trawlllight and TLUtilities from their GitHub repositories. Functions in the trawllight pacakage have full documentation. Not all functions in TLUtilities currently have documentation.

```{r install}
library(trawllight)
library(TLUtilities)
```

## Import directory structure

TLUtilities requires the user to pass a character vector indicating where light data are maintained. Each directory should contain a single file names  CastTimes.csv, a single file named corr_Mk9Hauls.csv, and any number (including zero) of files named deck**.csv. The CastTimes.csv files contains survey event times associated with cast start/stop. The corr_Mk9.Hauls.csv file contains data from a TDR-Mk9 archival tag with time-stamps shifted to match 'survey' time in cases where temporal drift occurred.

```{r import}
light.dir <- read.csv("./imports/directories.csv", stringsAsFactors = F, header = F)

# Select EBS shelf directories
light.dir <- light.dir[which(grepl("ebs", light.dir[,1])),1]

light.dir[1:3]
```


## Read-in and process trawl light data

The `process_all` function is a wrapper which runs `vertical_profiles`, `trawllight::convert_light`, `trawllight::filter_stepwise`, `trawllight::calculate_attenuation` for every cast in each of the target directories. The `vertical_profiles` function uses CastTimes to extract the light measurements from corr_Mk9Hauls.csv which were obtained during upcasts or downcasts. A time buffer can be specified to extend the cast time window, and seems necessary to handle situations where cast times are not perfectly accurate. Other arguments can be passed to the functions which are used for processing each cast.

Downcasts and Upcasts should be processed in separate function calls, but multiple years can be processed using one funciton call. Processing should be limited to 4-6 vessel/cruise combinations to avoid issues with R memory limits (which can substantially increase processing time or cause R to crash). Here, processing is demonstrated for one vessel and one year.

```{r warning = FALSE}
ebs <- process_all(dir.structure = light.dir[10:12],
                   cast.dir = "Downcast",
                   time.buffer = 20,
                   silent = T)
```

## Vertical profiles

A list containing four data frames gets returned by `process_all`: 
* `loess_eval` contains information about loess model fits between depth and log(light), with one record for each model that was fitted.
* `resid_fit` contains depth-specific residuals for each fitted loess model.
* `atten_values` contains instantaneous attenuation, by user-specified depth intervals, for each cast.
* `light_ratios` contains converted light measurements and proportion of light relative to the shallowest depth bin, for each depth bin and cast. For cases when the shallowest depth bin is equal to the reference depth: light_ratios$light_ratio = exp(-[Optical Depth]

```{r}
names(ebs)
head(ebs$loess_eval)
head(ebs$resid_fit)
head(ebs$atten_values)
head(ebs$light_ratios)

```

## Read-in surface (deck) light data

The `process_all_surface()` function is a wrapper which runs `TLUtilities::surface_light` and `trawllight::convert_light()` for every vessel/cruise/haul in each of the specified directories. If time_adjustments is TRUE, the function also runs `TLUtilities::time_adjustments`.

The `surface_light` function finds surface light measurements which were obtained between the beginning and end of a cast, plus a time buffer in seconds. 

The `time_adjustments` function adjusts timestamps from the surface light meter to account for a mismatch between tag time and survey time. However, the function only provides an example of how I made corrrections, so <b>time_adjustments.R</b> will need to have logical operations rewritten to correct timestamps in other regions. I determined what the offsets should be by visually inpsecting plots of time versus surface light, and time versus predicted light generated by a global irradiance model.

All directories can be processed in one function call. The function should automatically ignore years where no deck**.csv file is found in a directory. Measurements obtained during upcasts and downcasts can be obtained at the same time. This code only processes eight vessel/cruises (for a reason):

```{r}
ebs_surface <- process_all_surface(dir.structure = light.dir[c(1, 5, 10:15)], adjust.time = F, time.buffer = 30, agg.fun = geometric.mean)
```
Note that `time_adjustments` applied a user-specified correction to 162-201101.

```{r}
head(ebs_surface)
table(ebs_surface$updown, ebs_surface$cruise)
```

We see data from five years. The first directory contained 2004 survey data, a year where surface tag were not deployed.

## Check for surface measurement errors

In my workflow, this seemed like the correct time to check for measurement errors. You could certainly check for errors earlier, but I found problems were easier to detect when inspecting multiple years of data. Here, I read-in haul time/position data from an `.rds` file. The time format is already in POSIXct and all of the column names are lower case so they match column names in the ebs_surface data frame. I only used downcasts for this example but casts in both directions could be handled at the same time with a few extra lines of code.

```{r}
haul.dat <- readRDS("./data/haul_time_position.rds")
str(haul.dat)
ebs_surface.haul <- merge(ebs_surface, haul.dat)
ebs_surface.haul <- subset(ebs_surface.haul, updown == "Downcast")
```

I used `fishmethods::astrocalc4R` to model light (clear-sky PAR) at the sea surface for downcasts based on haul time and position. Functions in the package `lubridate` are used to find date/time components. Note that astrocalc4R is vectorized and the timezone of the timestamps needs to be specified as vector with length equal to your other arguments.
```{r}
library(fishmethods)
library(lubridate)

ebs_surface.haul <- cbind(ebs_surface.haul,
                          astrocalc4r(day = day(ebs_surface.haul$start_time), 
                                      month = month(ebs_surface.haul$start_time), 
                                      year = year(ebs_surface.haul$start_time), 
                                      hour = hour(ebs_surface.haul$start_time) + minute(ebs_surface.haul$start_time)/60, 
                                      timezone = rep(-8, nrow(ebs_surface.haul)), 
                                      lat = ebs_surface.haul$start_latitude, 
                                      lon = ebs_surface.haul$start_longitude))
head(ebs_surface.haul)
```

The column we're interested in here is PAR. Some plots help figure out where errors occur. I added an offset to PAR because the solar irradiance model. I've added a small value to PAR because the model generates really low PAR when the sun is very low (or below) the horizon, which makes plotting somewhat useless.

```{r}
library(ggplot2)

ggplot(data = ebs_surface.haul) + 
  geom_point(aes(x = log10(PAR + 0.001), y = log10(surf_trans_llight), color = paste(vessel, cruise, sep = "/"))) + 
  geom_smooth(aes(x = log10(PAR + 0.001), y = log10(surf_trans_llight))) +
    scale_color_discrete(name = "Vessel/Cruise") 

```

From the plot, it looks like there were problems with surface measurements from 134/200601 and 162/201101. See the vignette named 'Surface Errors' to see how I figured out what the problems were. 

I modified the file time_adjustments.R to make corrections to timestamps, then re-ran the surface wrapper function with `time.adjust` set to `TRUE`.

```{r}
ebs_surface <- process_all_surface(dir.structure = light.dir[c(1, 5, 10:15)], adjust.time = T, time.buffer = 30)
```

After time adjustments, the relationship looks much better:
```{r echo = F}
ebs_surface.haul <- subset(merge(ebs_surface, haul.dat), updown == "Downcast")
ebs_surface.haul <- cbind(ebs_surface.haul,
                          astrocalc4r(day = day(ebs_surface.haul$start_time), 
                                      month = month(ebs_surface.haul$start_time), 
                                      year = year(ebs_surface.haul$start_time), 
                                      hour = hour(ebs_surface.haul$start_time) + minute(ebs_surface.haul$start_time)/60, 
                                      timezone = rep(-8, nrow(ebs_surface.haul)), 
                                      lat = ebs_surface.haul$start_latitude, 
                                      lon = ebs_surface.haul$start_longitude, 
                                      seaorland = "maritime"))
ggplot(data = ebs_surface.haul) + 
  geom_point(aes(x = log10(PAR + 0.001), y = log10(surf_trans_llight), color = paste(vessel, cruise, sep = "/"))) + 
  geom_smooth(aes(x = log10(PAR + 0.001), y = log10(surf_trans_llight))) +
    scale_color_discrete(name = "Vessel/Cruise") 
```

## Detecting tag obstruction

Now that I have extracted measurements from the trawl-mounted archival tag and deck-mounted archival tag, it's time to test for measurement errors caused by obstruction of the photoelectric cell on the archival tag. Two methods are described below. I consider the direct method to be preferable to the indirect method because it utilizes light measurements wheras the indirect method is based on a solar irradiance model.

*<b>Direct method:</b> Fit a linear model between surface light measurements and trawl light measurements near the sea surface. Use the distribution of model residual  to assign a threshold below which measurements should be considered to be obstructed. 

*<b>Indirect method:</b> Fit a generalized additive model between model estimates of photosynthetically available radiation (400-700 nm) at the sea surface and trawl light measurements near the sea surface. This method uses a solar irradiance model (Frouin et al. 1989), implemented in the `fishmethods` package, to estimate solar irradiance at the sea surface based on cast time and position. The model assumes clear sky (no clouds).

Functions for the direct method and indirect method are vectorized functions in `trawllight`. The `TLUtilities` package includes wrapper functions to loop over the `trawllight` functions based on our data structure. 

#### Direct method

Arguments passed to the direct method function are:
*`x` A data frame which should contain all of the `light_ratios` returned by `process_all`, along with the surface light measurements for each casts, which are returned by `process_all_surface`.
*`forumla` This is the forumla that gets passed to `lm`, from which residuals are obtained. The formula for the best-fitting model in the EBS is provided in the code below. I have an R file with all of the code to test for effects of sea state but it is not included in `TLUtilities`.
*`water.col` Character vector of length one which contains the name of the column with trawl light measurements.
*`surface.col` Character vector of length one which contains the name of the column with surface light measurements.
*`depth.col` Character vector of length one which contains the name of the column with depth measurements.
*`depth.col` Depth bins which should be used for measurement error detection. A different model is fit to measurements from each depth bin.

```{r}
library(plyr)
x <- merge(ebs$light_ratios, ebs_surface.haul)

direct_residuals <- tag_residuals_direct(x = x, formula = log10(trans_llight) ~ log10(surf_trans_llight) + interaction(vessel, cruise),
                                  water.col = "trans_llight", 
                                  surface.col = "surf_trans_llight", 
                                  depth.col = "cdepth", 
                                  depth.bins = c(1, 3, 5))
head(direct_residuals)

```

The `trawllight::tag_residuals_direct` function returns a data frame which includes raw residuals from the linear model. The `direct_residual` column is the column of interest. Note that it is in log<sub>10</sub>-space.

Kernel density distribution of residuals:
```{r}
ggplot(data = direct_residuals, aes(x = direct_residual)) + geom_density() + facet_wrap(~cdepth, nrow = 1)
```

#### Indirect method

The `trawllight::tag_residuals_indirect` function requires the following arguments:
* `x` A data frame which should contain all of the `light_ratios` returned by `process_all`.
* `formula` Model formula passed to mgcv::gam
* `utc.offset` The timezone in the data frame relative to UTC. -8 for summer surveys
* `lat.col`, `lon.col`, `time.col`, `light.col` Names of columns containing necessary data. See function documentation for details.

```{r}
tag_residuals_indirect(x = x, 
                       formula = log10(trans_llight) ~ s(PAR, bs = "cr"),
                       utc.offset = -8,
                       lat.col = "start_latitude",
                       lon.col = "start_longitude",
                       time.col = "start_time",
                       light.col = "trans_llight")
```


#### Alternative methods

I explored some additional options for threshold-based rejection of casts. The sequential outlier rejection algorithm is implemented in TLUtilities as `sequentialOR`. The function includes documentation (`?sequentialOR`) and a vignette. I've also explored using extreme value analysis, but it is not currently implemented in TLUtilities. Both sequential outlier rejection and extreme value analysis require selection of a probablity density function for modelling error.
